


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Uncertain Inputs with Gaussian Processes">
      
      
        <link rel="canonical" href="https://jejjohnson.github.io/uncertain_gps/notebooks/1.0_gp_basics/">
      
      
        <meta name="author" content="J. Emmanuel Johnson">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1, mkdocs-material-5.1.4">
    
    
      
        <title>1.0 gp basics - Uncertain Gaussian Processes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.c4007cdc.min.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/palette.8435c73a.min.css">
      
      
        
        
        <meta name="theme-color" content="">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=source+code+pro:300,400,400i,700%7Csource+code+pro&display=fallback">
        <style>body,input{font-family:"source code pro",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"source code pro",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    
      
    
    
  </head>
  
  
    
    
    <body dir="ltr" data-md-color-primary="black" data-md-color-accent="gray">
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#gaussian-process-regression" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="https://jejjohnson.github.io/uncertain_gps" title="Uncertain Gaussian Processes" class="md-header-nav__button md-logo" aria-label="Uncertain Gaussian Processes">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Uncertain Gaussian Processes
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              1.0 gp basics
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/jejjohnson/uncertain_gps/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/uncertain_gps
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://jejjohnson.github.io/uncertain_gps" title="Uncertain Gaussian Processes" class="md-nav__button md-logo" aria-label="Uncertain Gaussian Processes">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Uncertain Gaussian Processes
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/jejjohnson/uncertain_gps/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    jejjohnson/uncertain_gps
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Input Uncertainty for Gaussian Processes" class="md-nav__link">
      Input Uncertainty for Gaussian Processes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../basics/" title="Gaussian Process Basics" class="md-nav__link">
      Gaussian Process Basics
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../error_propagation/" title="Error Propagation" class="md-nav__link">
      Error Propagation
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../literature/" title="Uncertain Inputs in Gaussian Processes" class="md-nav__link">
      Uncertain Inputs in Gaussian Processes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../mm/" title="Moment-Matching" class="md-nav__link">
      Moment-Matching
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../next/" title="Next Steps" class="md-nav__link">
      Next Steps
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../software/" title="Software" class="md-nav__link">
      Software
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../stochastic/" title="Stochastic" class="md-nav__link">
      Stochastic
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../taylor/" title="Linearization (Taylor Expansions)" class="md-nav__link">
      Linearization (Taylor Expansions)
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../uncertainty/" title="What is Uncertainty?" class="md-nav__link">
      What is Uncertainty?
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../vi/" title="Uncertain Inputs GPs - Variational Strategies" class="md-nav__link">
      Uncertain Inputs GPs - Variational Strategies
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-12" type="checkbox" id="nav-12" checked>
    
    <label class="md-nav__link" for="nav-12">
      Notebooks
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Notebooks" data-md-level="1">
      <label class="md-nav__title" for="nav-12">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Notebooks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        1.0 gp basics
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="1.0 gp basics" class="md-nav__link md-nav__link--active">
      1.0 gp basics
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#imports" class="md-nav__link">
    Imports
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    Data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-process" class="md-nav__link">
    Gaussian Process
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-gp-prior" class="md-nav__link">
    Model: GP Prior
  </a>
  
    <nav class="md-nav" aria-label="Model: GP Prior">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kernel-function" class="md-nav__link">
    Kernel Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-matrix" class="md-nav__link">
    Kernel Matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-function" class="md-nav__link">
    Mean Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-compute-model" class="md-nav__link">
    3. Compute Model
  </a>
  
    <nav class="md-nav" aria-label="3. Compute Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#checks" class="md-nav__link">
    Checks
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-sampling-from-gp-prior" class="md-nav__link">
    4. Sampling from GP Prior
  </a>
  
    <nav class="md-nav" aria-label="4. Sampling from GP Prior">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scipy" class="md-nav__link">
    Scipy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#note-the-positive-semi-definite-error" class="md-nav__link">
    Note - The positive semi-definite error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jax" class="md-nav__link">
    Jax
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-posterior" class="md-nav__link">
    4. Posterior
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-loss-log-likelihood" class="md-nav__link">
    5. Loss - Log-Likelihood
  </a>
  
    <nav class="md-nav" aria-label="5. Loss - Log-Likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#from-scratch" class="md-nav__link">
    From Scratch
  </a>
  
    <nav class="md-nav" aria-label="From Scratch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#auto-batching-with-vmap" class="md-nav__link">
    Auto-Batching with VMAP
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refactor-built-in-function" class="md-nav__link">
    Refactor - Built-in Function
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-training" class="md-nav__link">
    6. Training
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-predictions" class="md-nav__link">
    7. Predictions
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1.1_gp_refactored/" title="1.1 gp refactored" class="md-nav__link">
      1.1 gp refactored
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2.0_linearized_gp/" title="2.0 linearized gp" class="md-nav__link">
      2.0 linearized gp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.0_unscented_gp/" title="3.0 unscented gp" class="md-nav__link">
      3.0 unscented gp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../distances/" title="Distances" class="md-nav__link">
      Distances
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../egp_pyro_svgp/" title="Egp pyro svgp" class="md-nav__link">
      Egp pyro svgp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../egp_pyro_vgp/" title="Egp pyro vgp" class="md-nav__link">
      Egp pyro vgp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../kernel_derivatives/" title="Kernel derivatives" class="md-nav__link">
      Kernel derivatives
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpyro_egp_mcmc/" title="Numpyro egp mcmc" class="md-nav__link">
      Numpyro egp mcmc
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-13" type="checkbox" id="nav-13">
    
    <label class="md-nav__link" for="nav-13">
      Talks
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Talks" data-md-level="1">
      <label class="md-nav__title" for="nav-13">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Talks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../talks/2020_kermes/" title="KERMES Meetup 2020" class="md-nav__link">
      KERMES Meetup 2020
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#imports" class="md-nav__link">
    Imports
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    Data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussian-process" class="md-nav__link">
    Gaussian Process
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-gp-prior" class="md-nav__link">
    Model: GP Prior
  </a>
  
    <nav class="md-nav" aria-label="Model: GP Prior">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kernel-function" class="md-nav__link">
    Kernel Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kernel-matrix" class="md-nav__link">
    Kernel Matrix
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-function" class="md-nav__link">
    Mean Function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-compute-model" class="md-nav__link">
    3. Compute Model
  </a>
  
    <nav class="md-nav" aria-label="3. Compute Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#checks" class="md-nav__link">
    Checks
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-sampling-from-gp-prior" class="md-nav__link">
    4. Sampling from GP Prior
  </a>
  
    <nav class="md-nav" aria-label="4. Sampling from GP Prior">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scipy" class="md-nav__link">
    Scipy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#note-the-positive-semi-definite-error" class="md-nav__link">
    Note - The positive semi-definite error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jax" class="md-nav__link">
    Jax
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-posterior" class="md-nav__link">
    4. Posterior
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-loss-log-likelihood" class="md-nav__link">
    5. Loss - Log-Likelihood
  </a>
  
    <nav class="md-nav" aria-label="5. Loss - Log-Likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#from-scratch" class="md-nav__link">
    From Scratch
  </a>
  
    <nav class="md-nav" aria-label="From Scratch">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#auto-batching-with-vmap" class="md-nav__link">
    Auto-Batching with VMAP
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#refactor-built-in-function" class="md-nav__link">
    Refactor - Built-in Function
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-training" class="md-nav__link">
    6. Training
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-predictions" class="md-nav__link">
    7. Predictions
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/jejjohnson/uncertain_gps/edit/master/docs/notebooks/1.0_gp_basics.ipynb" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script>
(function() {
  function addWidgetsRenderer() {
    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var scriptElement = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    scriptElement.src = widgetRendererSrc;
    document.body.appendChild(scriptElement);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h1 id="gaussian-process-regression">Gaussian Process Regression<a class="headerlink" href="#gaussian-process-regression" title="Permanent link">&para;</a></h1>
<p>This notebook, I will go over how we can implement the Gaussian process (GP) regression algorithm using Jax. This isn't a new algorithm or anything but I would like to get accustomed to using Jax because it will be useful later when I implement the GPs to handle uncertain inputs.</p>
<p><strong>Inspirations</strong></p>
<ul>
<li><a href="https://github.com/lucasrm25/Structured-Learning-for-Robot-Control/blob/master/GP/jaxGP.py">Github Code</a> - <a href="https://www.linkedin.com/in/lucas-rath/?originalSubdomain=bo">Lucas</a><blockquote>
<p>Broke down the GP function very nicely. Nice enough for me to follow.
</div>
</div></p>
</blockquote>
</li>
</ul>
</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="imports">Imports<a class="headerlink" href="#imports" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">functools</span>

<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax.experimental</span> <span class="kn">import</span> <span class="n">optimizers</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">onp</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>


<span class="c1"># Plotting libraries</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">&#39;seaborn-paper&#39;</span><span class="p">])</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="data">Data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">sigma_obs</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">N_test</span><span class="o">=</span><span class="mi">400</span><span class="p">):</span>
    <span class="n">onp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">4.0</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">+=</span> <span class="n">sigma_obs</span> <span class="o">*</span> <span class="n">onp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">-=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">/=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">N</span><span class="p">,)</span>
    <span class="k">assert</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">N</span><span class="p">,)</span>

    <span class="n">X_test</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">N_test</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="kc">None</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(30, 1) (30, 1)
</pre>
</div>
</div>

<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="gaussian-process">Gaussian Process<a class="headerlink" href="#gaussian-process" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="model-gp-prior">Model: GP Prior<a class="headerlink" href="#model-gp-prior" title="Permanent link">&para;</a></h2>
<p><strong>Parameters</strong>:</p>
</div>
</div>
<ul>
<li>
<p>X, Y, $\theta= $ (Likelihood Parameters, Kernel Parameters)</p>
</li>
<li>
<p>Compute the Kernel Matrix</p>
</li>
<li>Compute the Mean function</li>
<li>Sample from the Multivariate Normal Distribution
</div>
</div></li>
</ul>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="kernel-function">Kernel Function<a class="headerlink" href="#kernel-function" title="Permanent link">&para;</a></h3>
<p><span><span class="MathJax_Preview"><span><span class="MathJax_Preview">k(x,y) = \sigma_f \exp \left( - \frac{1}{2\sigma_\lambda^2}|| x - y||^2_2 \right)</span><script type="math/tex">k(x,y) = \sigma_f \exp \left( - \frac{1}{2\sigma_\lambda^2}|| x - y||^2_2 \right)</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">k(x,y) = \sigma_f \exp \left( - \frac{1}{2\sigma_\lambda^2}|| x - y||^2_2 \right)</span><script type="math/tex">k(x,y) = \sigma_f \exp \left( - \frac{1}{2\sigma_\lambda^2}|| x - y||^2_2 \right)</script></span></script></span>
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Squared Euclidean Distance Formula</span>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">sqeuclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># RBF Kernel</span>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">rbf_kernel</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">sqeuclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="c1"># ARD Kernel</span>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">ard_kernel</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

    <span class="c1"># divide by the length scale</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">/</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;length_scale&#39;</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;length_scale&#39;</span><span class="p">]</span>

    <span class="c1"># return the ard kernel</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;var_f&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span> <span class="n">sqeuclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;sigma&#39;</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="p">}</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="kernel-matrix">Kernel Matrix<a class="headerlink" href="#kernel-matrix" title="Permanent link">&para;</a></h3>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Gram Matrix</span>
<span class="k">def</span> <span class="nf">gram</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x1</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y1</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">))(</span><span class="n">y</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;likelihood_noise&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">}</span>
<span class="c1"># input vector</span>
<span class="c1"># x_plot = jnp.linspace(X.min(), X.max(), 100)[:, None]</span>
<span class="c1"># test_X = x_plot[0, :]</span>


<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>
<span class="n">K_</span> <span class="o">=</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">K_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">K_</span> <span class="o">=</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">K_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(400, 30)
(30, 400)
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="mean-function">Mean Function<a class="headerlink" href="#mean-function" title="Permanent link">&para;</a></h3>
</div>
</div>
<p>Honestly, I never work with mean functions. I always assume a zero-mean function and that's it. I don't really know anyone who works with mean functions either. I've seen it used in deep Gaussian processes but I have no expertise in which mean functions to use. So, we'll follow the community standard for now: zero mean function
</div>
</div></p>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">zero_mean</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="3-compute-model">3. Compute Model<a class="headerlink" href="#3-compute-model" title="Permanent link">&para;</a></h3>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
Now we have all of the components to make our GP prior function.
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">,</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># define mean function</span>
<span class="n">mu_f</span> <span class="o">=</span> <span class="n">zero_mean</span>

<span class="c1"># define covariance function</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="p">}</span>

<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>

<span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h4 id="checks">Checks<a class="headerlink" href="#checks" title="Permanent link">&para;</a></h4>
<p>So I'm still getting used to the <code>vmap</code>. So in theory, this function should work for a vector <span><span class="MathJax_Preview">\mathbf{x} \in \mathbb{R}^{D}</span><script type="math/tex">\mathbf{x} \in \mathbb{R}^{D}</script></span> and for a batch of samples <span><span class="MathJax_Preview">X \in \mathbb{R}^{N \times D}</span><script type="math/tex">X \in \mathbb{R}^{N \times D}</script></span>
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># checks - 1 vector (D)</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span> 

<span class="nb">print</span><span class="p">(</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">mu_x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<span class="c1"># Check output shapes, # of dimensions</span>
<span class="k">assert</span> <span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">cov_x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> 


<span class="c1"># checks - 1 vector with batch size (NxD)</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span> 


<span class="k">assert</span> <span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">mu_x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<span class="c1"># Check output shapes, # of dimensions</span>
<span class="k">assert</span> <span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">cov_x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[30,1]), ShapedArray(float32[30,1])).
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(1,) (1, 1)
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
Woot! Success! So now we can technically sample from this GP prior distribution.
</div>
</div></p>
</div>
<div class="cell border-box-sizing text_cell rendered"></div>
</div>
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="4-sampling-from-gp-prior">4. Sampling from GP Prior<a class="headerlink" href="#4-sampling-from-gp-prior" title="Permanent link">&para;</a></h3>
<p></div>
</div></p>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span> <span class="k">as</span> <span class="n">scio_mvn</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h4 id="scipy">Scipy<a class="headerlink" href="#scipy" title="Permanent link">&para;</a></h4>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># checks - 1 vector (D)</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;length_scale&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> 
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> 
<span class="p">}</span>


<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>                   <span class="c1"># condition on 3 samples </span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># random samples from distribution</span>

<span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span> <span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span>

<span class="c1"># check outputs</span>
<span class="k">assert</span> <span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,)</span>
<span class="k">assert</span> <span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

<span class="c1"># draw random samples from distribution</span>
<span class="n">n_functions</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">y_samples</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mu_x</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_functions</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">y_samples</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_functions</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

<span class="k">for</span> <span class="n">isample</span> <span class="ow">in</span> <span class="n">y_samples</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">isample</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-182-7c0d1026349a&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      9</span> test_X <span class="ansi-blue-fg">=</span> X<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span>n_samples<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>copy<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># random samples from distribution</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-fg">---&gt; 11</span><span class="ansi-red-fg"> </span>mu_x<span class="ansi-blue-fg">,</span> cov_x <span class="ansi-blue-fg">=</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">=</span>mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">=</span>cov_f <span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">=</span>test_X<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span> 
<span class="ansi-green-intense-fg ansi-bold">     13</span> <span class="ansi-red-fg"># check outputs</span>

<span class="ansi-green-fg">&lt;ipython-input-178-5213747816ca&gt;</span> in <span class="ansi-cyan-fg">gp_prior</span><span class="ansi-blue-fg">(params, mu_f, cov_f, x)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">def</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> mu_f<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">gram</span><span class="ansi-blue-fg">(func, params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(x1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(y1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-173-a1a5400824ce&gt;</span> in <span class="ansi-cyan-fg">rbf_kernel</span><span class="ansi-blue-fg">(params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> <span class="ansi-red-fg"># @jax.jit</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> <span class="ansi-green-fg">def</span> rbf_kernel<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 9</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jnp<span class="ansi-blue-fg">.</span>exp<span class="ansi-blue-fg">(</span> <span class="ansi-blue-fg">-</span> params<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;gamma&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">*</span> sqeuclidean_distance<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-intense-fg ansi-bold">     11</span> <span class="ansi-red-fg"># ARD Kernel</span>

<span class="ansi-red-fg">KeyError</span>: &#39;gamma&#39;</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h4 id="note-the-positive-semi-definite-error">Note - The positive semi-definite error<a class="headerlink" href="#note-the-positive-semi-definite-error" title="Permanent link">&para;</a></h4>
<p>I believe that's due to the diagonals being off. Normally we add something called jitter. This allows the matrix to be positive semi-definite.
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span> <span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span>

<span class="c1"># make it semi-positive definite with jitter</span>
<span class="n">jitter</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">cov_x_</span> <span class="o">=</span> <span class="n">cov_x</span> <span class="o">+</span> <span class="n">jitter</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># draw random samples from distribution</span>
<span class="n">n_functions</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">y_samples</span> <span class="o">=</span> <span class="n">scio_mvn</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mu_x</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_x_</span> <span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_functions</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">isample</span> <span class="ow">in</span> <span class="n">y_samples</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">isample</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-183-12ab200a8e55&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>mu_x<span class="ansi-blue-fg">,</span> cov_x <span class="ansi-blue-fg">=</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">=</span>mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">=</span>cov_f <span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">=</span>test_X<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> 
<span class="ansi-green-intense-fg ansi-bold">      3</span> <span class="ansi-red-fg"># make it semi-positive definite with jitter</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> jitter <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1e-6</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> cov_x_ <span class="ansi-blue-fg">=</span> cov_x <span class="ansi-blue-fg">+</span> jitter <span class="ansi-blue-fg">*</span> np<span class="ansi-blue-fg">.</span>eye<span class="ansi-blue-fg">(</span>cov_x<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-178-5213747816ca&gt;</span> in <span class="ansi-cyan-fg">gp_prior</span><span class="ansi-blue-fg">(params, mu_f, cov_f, x)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">def</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> mu_f<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">gram</span><span class="ansi-blue-fg">(func, params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(x1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(y1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-173-a1a5400824ce&gt;</span> in <span class="ansi-cyan-fg">rbf_kernel</span><span class="ansi-blue-fg">(params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> <span class="ansi-red-fg"># @jax.jit</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> <span class="ansi-green-fg">def</span> rbf_kernel<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 9</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jnp<span class="ansi-blue-fg">.</span>exp<span class="ansi-blue-fg">(</span> <span class="ansi-blue-fg">-</span> params<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;gamma&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">*</span> sqeuclidean_distance<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-intense-fg ansi-bold">     11</span> <span class="ansi-red-fg"># ARD Kernel</span>

<span class="ansi-red-fg">KeyError</span>: &#39;gamma&#39;</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
And now we don't have that message. This is a small thing but it's super important and can lead to errors in the optimization if not addressed.
</div>
</div></p>
</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h4 id="jax">Jax<a class="headerlink" href="#jax" title="Permanent link">&para;</a></h4>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

</div>
</div>
</div>
<div class="highlight"><pre><span></span><code><span class="c1"># checks - 1 vector (D)</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;length_scale&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> 
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> 
<span class="p">}</span>


<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>                   <span class="c1"># condition on 3 samples </span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># random samples from distribution</span>

<span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_f</span> <span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span>

<span class="c1"># make it semi-positive definite with jitter</span>
<span class="n">jitter</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">cov_x_</span> <span class="o">=</span> <span class="n">cov_x</span> <span class="o">+</span> <span class="n">jitter</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">cov_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>


<span class="n">n_functions</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">y_samples</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">mu_x</span><span class="p">,</span> <span class="n">cov_x_</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_functions</span><span class="p">,))</span>

<span class="c1"># check</span>
<span class="k">assert</span> <span class="n">y_samples</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_functions</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

<span class="k">for</span> <span class="n">isample</span> <span class="ow">in</span> <span class="n">y_samples</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">isample</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-184-9b06421fbf35&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      9</span> test_X <span class="ansi-blue-fg">=</span> X<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span>n_samples<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>copy<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># random samples from distribution</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-fg">---&gt; 11</span><span class="ansi-red-fg"> </span>mu_x<span class="ansi-blue-fg">,</span> cov_x <span class="ansi-blue-fg">=</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">=</span>mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">=</span>cov_f <span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">=</span>test_X<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span> 
<span class="ansi-green-intense-fg ansi-bold">     13</span> <span class="ansi-red-fg"># make it semi-positive definite with jitter</span>

<span class="ansi-green-fg">&lt;ipython-input-178-5213747816ca&gt;</span> in <span class="ansi-cyan-fg">gp_prior</span><span class="ansi-blue-fg">(params, mu_f, cov_f, x)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">def</span> gp_prior<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> mu_f<span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> mu_f<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">,</span> cov_f<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">gram</span><span class="ansi-blue-fg">(func, params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(x1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/api.py</span> in <span class="ansi-cyan-fg">batched_fun</span><span class="ansi-blue-fg">(*args)</span>
<span class="ansi-green-intense-fg ansi-bold">    756</span>     in_axes_flat <span class="ansi-blue-fg">=</span> _flatten_axes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> in_axes<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>     _check_axis_sizes<span class="ansi-blue-fg">(</span>in_tree<span class="ansi-blue-fg">,</span> args_flat<span class="ansi-blue-fg">,</span> in_axes_flat<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 758</span><span class="ansi-red-fg">     out_flat = batching.batch(flat_fun, args_flat, in_axes_flat,
</span><span class="ansi-green-intense-fg ansi-bold">    759</span>                               lambda: _flatten_axes(out_tree(), out_axes))
<span class="ansi-green-intense-fg ansi-bold">    760</span>     <span class="ansi-green-fg">return</span> tree_unflatten<span class="ansi-blue-fg">(</span>out_tree<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> out_flat<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/interpreters/batching.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(fun, in_vals, in_dims, out_dim_dests)</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>   <span class="ansi-red-fg"># executes a batched version of `fun` following out_dim_dests</span>
<span class="ansi-green-intense-fg ansi-bold">     33</span>   batched_fun <span class="ansi-blue-fg">=</span> batch_fun<span class="ansi-blue-fg">(</span>fun<span class="ansi-blue-fg">,</span> in_dims<span class="ansi-blue-fg">,</span> out_dim_dests<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 34</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> batched_fun<span class="ansi-blue-fg">.</span>call_wrapped<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>in_vals<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     35</span> 
<span class="ansi-green-intense-fg ansi-bold">     36</span> <span class="ansi-blue-fg">@</span>lu<span class="ansi-blue-fg">.</span>transformation_with_aux

<span class="ansi-green-fg">~/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/linear_util.py</span> in <span class="ansi-cyan-fg">call_wrapped</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span>     gen <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span> 
<span class="ansi-green-fg">--&gt; 150</span><span class="ansi-red-fg">     </span>ans <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>dict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>params<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>     <span class="ansi-green-fg">del</span> args
<span class="ansi-green-intense-fg ansi-bold">    152</span>     <span class="ansi-green-fg">while</span> stack<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-175-6d9cf91bb78f&gt;</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(y1)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Gram Matrix</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">def</span> gram<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> x1<span class="ansi-blue-fg">:</span> jax<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">lambda</span> y1<span class="ansi-blue-fg">:</span> func<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x1<span class="ansi-blue-fg">,</span> y1<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-173-a1a5400824ce&gt;</span> in <span class="ansi-cyan-fg">rbf_kernel</span><span class="ansi-blue-fg">(params, x, y)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> <span class="ansi-red-fg"># @jax.jit</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> <span class="ansi-green-fg">def</span> rbf_kernel<span class="ansi-blue-fg">(</span>params<span class="ansi-blue-fg">,</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 9</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> jnp<span class="ansi-blue-fg">.</span>exp<span class="ansi-blue-fg">(</span> <span class="ansi-blue-fg">-</span> params<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;gamma&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">*</span> sqeuclidean_distance<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-intense-fg ansi-bold">     11</span> <span class="ansi-red-fg"># ARD Kernel</span>

<span class="ansi-red-fg">KeyError</span>: &#39;gamma&#39;</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="4-posterior">4. Posterior<a class="headerlink" href="#4-posterior" title="Permanent link">&para;</a></h2>
<p>Conditioned on the observations, can we make predictions.
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">,</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">cholesky_factorization</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>

    <span class="c1"># cho factor the cholesky</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ChoFactor: K</span><span class="si">{</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_factor</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, L: </span><span class="si">{</span><span class="n">L</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">L</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># weights</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, ChoSolve(L, Y): </span><span class="si">{</span><span class="n">L</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, alpha: </span><span class="si">{</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">L</span><span class="p">,</span> <span class="n">weights</span>

<span class="n">jitter</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">likelihood_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, X: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Y: </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, X*: </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="p">(</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_func</span><span class="p">)</span> <span class="o">=</span> <span class="n">prior_params</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded mean and cov functions&quot;</span><span class="p">)</span>

    <span class="c1"># ==========================</span>
    <span class="c1"># 1. GP PRIOR</span>
    <span class="c1"># ==========================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting GP Priors...&quot;</span><span class="p">)</span>

    <span class="n">mu_x</span><span class="p">,</span> <span class="n">Kxx</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_func</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, mu_x: </span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># check outputs</span>
    <span class="k">assert</span> <span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># ===========================</span>
    <span class="c1"># 2. CHOLESKY FACTORIZATION</span>
    <span class="c1"># ===========================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Solving Cholesky Factorization...&quot;</span><span class="p">)</span>

    <span class="c1"># 1 STEP</span>
<span class="c1">#     print(f&quot;Problem: {Kxx.shape},{Y.shape}&quot;)</span>
    <span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">cholesky_factorization</span><span class="p">(</span>
        <span class="n">Kxx</span> <span class="o">+</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;likelihood_noise&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">Y</span>
    <span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, L: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, alpha: </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;L:</span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= X..:</span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;alpha: </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= X: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># ================================</span>
    <span class="c1"># 4. PREDICTIVE MEAN DISTRIBUTION</span>
    <span class="c1"># ================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Projection Kernel...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, cov(x*, X): </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># calculate transform kernel</span>
    <span class="n">KxX</span> <span class="o">=</span> <span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, KxX: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="k">assert</span> <span class="n">KxX</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># Project data</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Mean Distribution...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, mu(x*): </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, KxX @ alpha: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> @ </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">mu_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, mu_y: </span><span class="si">{</span><span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># =====================================</span>
    <span class="c1"># 5. PREDICTIVE COVARIANCE DISTRIBUTION</span>
    <span class="c1"># =====================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Covariance matrix...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, L @ KxX.T: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> @ </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">#     print(f&quot;K_xX: {KXx.T.shape}, L: {L.shape}&quot;)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_solve</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, v: </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;v: </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix tests...cov(x*, x*)&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, cov(x*, x*) - </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Kxx</span> <span class="o">=</span> <span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X_new</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calculating final covariance matrix...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, v:</span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">cov_y</span> <span class="o">=</span> <span class="n">Kxx</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output: cov(x*, x*) - </span><span class="si">{</span><span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">likelihood_noise</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">cov_y</span> <span class="o">+=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;likelihood_noise&#39;</span><span class="p">]</span>

    <span class="c1"># TODO: Bug here for vmap...</span>

    <span class="c1"># =====================================</span>
    <span class="c1"># 6. PREDICTIVE VARIANCE DISTRIBUTION</span>
    <span class="c1"># =====================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Variance...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, L.T, I: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">Linv</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>


    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Linv: </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix tests...cov(x*, x*)&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, cov(x*, x*) - </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">var_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X_new</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, diag(Kxx): </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, Linv @ Linv.T - </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Kinv</span> <span class="o">=</span>  <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Linv</span><span class="p">,</span> <span class="n">Linv</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Kinv: </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final Variance...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, KxX: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">var_y</span> <span class="o">-=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ij-&gt;i&quot;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">Kinv</span><span class="p">),</span> <span class="n">KxX</span><span class="p">)</span> <span class="c1">#jnp.dot(jnp.dot(KxX, Kinv), KxX.T)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, var_y: </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1">#jnp.einsum(&quot;ij, jk, ki-&gt;i&quot;, KxX, jnp.dot(Linv, Linv.T), KxX.T)</span>

    <span class="k">return</span> <span class="n">mu_y</span><span class="p">,</span> <span class="n">cov_y</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov_y</span><span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="c1"># MEAN FUNCTION</span>
<span class="n">mu_f</span> <span class="o">=</span> <span class="n">zero_mean</span>

<span class="c1"># COVARIANCE FUNCTION</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;likelihood_noise&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>

<span class="c1"># input vector</span>
<span class="c1"># x_plot = jnp.linspace(X.min(), X.max(), 100)[:, None]</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">Xtest</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>

<span class="n">prior_funcs</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">)</span>

<span class="n">mu_y</span><span class="p">,</span> <span class="n">cov_y</span><span class="p">,</span> <span class="n">var_y</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_funcs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_new</span><span class="o">=</span><span class="n">test_X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:root:Inputs, X: (30, 1), Y: (30, 1), X*: (1,)
DEBUG:root:Loaded mean and cov functions
DEBUG:root:Getting GP Priors...
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[30,1]), ShapedArray(float32[30,1])).
DEBUG:root:Output, mu_x: (30,), Kxx: (30, 30)
DEBUG:root:Solving Cholesky Factorization...
DEBUG:root:ChoFactor: K(30, 30)
DEBUG:absl:Compiling _cholesky for args (ShapedArray(float32[30,30]),).
DEBUG:root:Output, L: (30, 30), True
DEBUG:root:Input, ChoSolve(L, Y): ((30, 30), (30, 1))
DEBUG:absl:Compiling _cho_solve for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,1])).
DEBUG:root:Output, alpha: (30, 1)
DEBUG:root:Output, L: (30, 30), alpha: (30, 1)
DEBUG:root:Getting Projection Kernel...
DEBUG:root:Input, cov(x*, X): (1,),(30, 1)
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[1]), ShapedArray(float32[30,1])).
DEBUG:root:Output, KxX: (1, 30)
DEBUG:root:Getting Predictive Mean Distribution...
DEBUG:root:Input, mu(x*): (1,), KxX @ alpha: (1, 30) @ (30, 1)
DEBUG:root:Output, mu_y: (1, 1)
DEBUG:root:Getting Predictive Covariance matrix...
DEBUG:root:Input, L @ KxX.T: (30, 30) @ (30, 1)
DEBUG:root:Output, v: (30, 1)
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (1,),(1,)
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[1]), ShapedArray(float32[1])).
DEBUG:root:Output, Kxx: (1, 1)
DEBUG:root:Calculating final covariance matrix...
DEBUG:root:Inputs, Kxx: (1, 1), v:(30, 1)
DEBUG:root:Output: cov(x*, x*) - (1, 1)
DEBUG:root:Getting Predictive Variance...
DEBUG:root:Input, L.T, I: (30, 30), (30, 1)
DEBUG:absl:Compiling _solve_triangular for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,30])).
DEBUG:root:Output, Linv: (30, 30), -6.00,7.19
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (1,),(1,)
DEBUG:absl:Compiling _where for args (ShapedArray(bool[1,1]), ShapedArray(float32[1,1]), ShapedArray(float32[1,1])).
DEBUG:root:Output, diag(Kxx): (1,), 1.00,1.00
DEBUG:root:Inputs, Linv @ Linv.T - (30, 30),(30, 30)
DEBUG:root:Output, Kinv: (30, 30), -33.54,86.93
DEBUG:root:Final Variance...
DEBUG:root:Inputs, KxX: (1, 30), (30, 30), (1, 30)
DEBUG:absl:Compiling _einsum for args (ShapedArray(float32[1,30]), ShapedArray(float32[1,30])).
DEBUG:root:Output, var_y: (1,), 0.03,0.03
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(1, 1) (1, 1) (1,)
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">mu_y</span><span class="p">,</span> <span class="n">cov_y</span><span class="p">,</span> <span class="n">var_y</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_funcs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:root:Inputs, X: (30, 1), Y: (30, 1), X*: (400, 1)
DEBUG:root:Loaded mean and cov functions
DEBUG:root:Getting GP Priors...
DEBUG:root:Output, mu_x: (30,), Kxx: (30, 30)
DEBUG:root:Solving Cholesky Factorization...
DEBUG:root:ChoFactor: K(30, 30)
DEBUG:root:Output, L: (30, 30), True
DEBUG:root:Input, ChoSolve(L, Y): ((30, 30), (30, 1))
DEBUG:root:Output, alpha: (30, 1)
DEBUG:root:Output, L: (30, 30), alpha: (30, 1)
DEBUG:root:Getting Projection Kernel...
DEBUG:root:Input, cov(x*, X): (400, 1),(30, 1)
DEBUG:root:Output, KxX: (400, 30)
DEBUG:root:Getting Predictive Mean Distribution...
DEBUG:root:Input, mu(x*): (400, 1), KxX @ alpha: (400, 30) @ (30, 1)
DEBUG:root:Output, mu_y: (400, 1)
DEBUG:root:Getting Predictive Covariance matrix...
DEBUG:root:Input, L @ KxX.T: (30, 30) @ (30, 400)
DEBUG:absl:Compiling _cho_solve for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,400])).
DEBUG:root:Output, v: (30, 400)
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (400, 1),(400, 1)
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[400,1]), ShapedArray(float32[400,1])).
DEBUG:root:Output, Kxx: (400, 400)
DEBUG:root:Calculating final covariance matrix...
DEBUG:root:Inputs, Kxx: (400, 400), v:(30, 400)
DEBUG:root:Output: cov(x*, x*) - (400, 400)
DEBUG:root:Getting Predictive Variance...
DEBUG:root:Input, L.T, I: (30, 30), (30, 400)
DEBUG:root:Output, Linv: (30, 30), -6.00,7.19
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (400, 1),(400, 1)
DEBUG:absl:Compiling _where for args (ShapedArray(bool[400,400]), ShapedArray(float32[400,400]), ShapedArray(float32[400,400])).
DEBUG:root:Output, diag(Kxx): (400,), 1.00,1.00
DEBUG:root:Inputs, Linv @ Linv.T - (30, 30),(30, 30)
DEBUG:root:Output, Kinv: (30, 30), -33.54,86.93
DEBUG:root:Final Variance...
DEBUG:root:Inputs, KxX: (400, 30), (30, 30), (400, 30)
DEBUG:absl:Compiling _einsum for args (ShapedArray(float32[400,30]), ShapedArray(float32[400,30])).
DEBUG:root:Output, var_y: (400,), 0.00,0.03
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(400, 1) (400, 400) (400,)
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">var_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f06943d8a30&gt;]</pre>
</div>

</div>

<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>((1,), (400, 1))</pre>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

</div>
</div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">uncertainty</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="n">uncertainty</span><span class="p">,</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">uncertainty</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mean&#39;</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f06741adfd0&gt;]</pre>
</div>

</div>

<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="5-loss-log-likelihood">5. Loss - Log-Likelihood<a class="headerlink" href="#5-loss-log-likelihood" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="from-scratch">From Scratch<a class="headerlink" href="#from-scratch" title="Permanent link">&para;</a></h3>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># @jax.jit</span>
<span class="k">def</span> <span class="nf">cholesky_factorization</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>

    <span class="c1"># cho factor the cholesky </span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_factor</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

    <span class="c1"># weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">L</span><span class="p">,</span> <span class="n">weights</span>

<span class="k">def</span> <span class="nf">nll_scratch</span><span class="p">(</span><span class="n">gp_priors</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>

    <span class="p">(</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_func</span><span class="p">)</span> <span class="o">=</span> <span class="n">gp_priors</span>

    <span class="c1"># ==========================</span>
    <span class="c1"># 1. GP PRIOR</span>
    <span class="c1"># ==========================</span>
    <span class="n">mu_x</span><span class="p">,</span> <span class="n">Kxx</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_func</span> <span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#     y_mean = jnp.mean(Y, axis=1)</span>
<span class="c1">#     Y -= y_mean</span>
<span class="c1">#     print(mu_x.shape, Kxx.shape)</span>

    <span class="c1"># ===========================</span>
    <span class="c1"># 2. CHOLESKY FACTORIZATION</span>
    <span class="c1"># ===========================</span>
<span class="c1">#     print(f&quot;Problem:&quot;, X.shape, Y.shape, Kxx.shape)</span>
<span class="c1">#     print(f&quot;Y: {Y.shape}, Kxx: {Kxx.shape}&quot;)</span>

    <span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">lower</span><span class="p">),</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">cholesky_factorization</span><span class="p">(</span><span class="n">Kxx</span> <span class="o">+</span> <span class="p">(</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;likelihood_noise&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-5</span> <span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">Y</span><span class="p">)</span>
<span class="c1">#     L = jax.scipy.linalg.cholesky(Kxx + ( params[&#39;likelihood_noise&#39;] + 1e-6 ) * jnp.eye(Kxx.shape[0]), lower=True)</span>
<span class="c1">#     alpha = jax.scipy.linalg.solve_triangular(L.T, jax.scipy.linalg.solve_triangular(L, y, lower=True))</span>
<span class="c1">#     print(f&quot;Y: {Y.shape}, alpha: {alpha.shape}&quot;)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Y: </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,alpha:</span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,ik-&gt;k&quot;</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span> <span class="c1">#* jnp.dot(Y.T, alpha) #</span>
    <span class="n">log_likelihood</span> <span class="o">-=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="p">)))</span>
    <span class="n">log_likelihood</span> <span class="o">-=</span> <span class="p">(</span> <span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span> <span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<span class="c1">#     log_likelihood -= jnp.sum(-0.5 * np.log(2 * 3.1415) - params[&#39;var_f&#39;]**2)</span>
    <span class="k">return</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">)</span>
<span class="c1"># #     print(L.shape, alpha.shape)</span>
<span class="c1">#     # cho factor the cholesky </span>
<span class="c1">#     K_gp = Kxx + ( params[&#39;likelihood_noise&#39;] + 1e-6 ) * jnp.eye(Kxx.shape[0])</span>
<span class="c1"># #     L = jax.scipy.linalg.cholesky(K_gp)</span>
<span class="c1"># #     assert np.testing.assert_array_almost_equal(K_gp, L @ L.T), </span>

<span class="c1">#     return jax.scipy.stats.multivariate_normal.logpdf(Y, mean=mu_x, cov=K_gp)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># MEAN FUNCTION</span>
<span class="n">mu_f</span> <span class="o">=</span> <span class="n">zero_mean</span>

<span class="c1"># COVARIANCE FUNCTION</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;likelihood_noise&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>


<span class="n">prior_funcs</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">)</span>
<span class="c1"># print(X.shape, y.shape, test_X.shape)</span>

<span class="n">nll</span> <span class="o">=</span> <span class="n">nll_scratch</span><span class="p">(</span><span class="n">prior_funcs</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nll</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:absl:Compiling _cholesky for args (ShapedArray(float32[30,30]),).
DEBUG:absl:Compiling _cho_solve for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,1])).
DEBUG:root:Y: (30, 1),alpha:(30, 1)
DEBUG:absl:Compiling _einsum for args (ShapedArray(float32[30,1]), ShapedArray(float32[30,1])).
DEBUG:absl:Compiling _where for args (ShapedArray(bool[30,30]), ShapedArray(float32[30,30]), ShapedArray(float32[30,30])).
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>54.878708
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h4 id="auto-batching-with-vmap">Auto-Batching with VMAP<a class="headerlink" href="#auto-batching-with-vmap" title="Permanent link">&para;</a></h4>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered"></div>
</div>
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">nll_scratch_vec</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">nll_scratch</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">nll</span> <span class="o">=</span> <span class="n">nll_scratch_vec</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_funcs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nll</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(1,) (1, 1)
Y: (1,), alpha: (1,)
-209.98637
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h3 id="refactor-built-in-function">Refactor - Built-in Function<a class="headerlink" href="#refactor-built-in-function" title="Permanent link">&para;</a></h3>
<p>It turns out that the jax library already has the <code>logpdf</code> for the <code>multivariate_normal</code> already implemented. So we can just use that.
</div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">,</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">marginal_likelihood</span><span class="p">(</span><span class="n">prior_params</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span>  <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">):</span>

    <span class="c1"># unpack params</span>
    <span class="p">(</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_func</span><span class="p">)</span> <span class="o">=</span> <span class="n">prior_params</span>

    <span class="c1"># ==========================</span>
    <span class="c1"># 1. GP Prior</span>
    <span class="c1"># ==========================</span>
    <span class="n">mu_x</span> <span class="o">=</span> <span class="n">mu_f</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mu: </span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Kxx</span> <span class="o">=</span> <span class="n">cov_f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">#     print(&quot;MLL (GPPR):&quot;, Xtrain.shape, Ytrain.shape)</span>
<span class="c1">#     mu_x, Kxx = gp_prior(params, mu_f=mu_func, cov_f=cov_func , x=Xtrain)</span>

    <span class="c1"># ===========================</span>
    <span class="c1"># 2. GP Likelihood</span>
    <span class="c1"># ===========================</span>
    <span class="n">K_gp</span> <span class="o">=</span> <span class="n">Kxx</span> <span class="o">+</span> <span class="p">(</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;likelihood_noise&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span> <span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K_gp: </span><span class="si">{</span><span class="n">K_gp</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">#     print(&quot;MLL (GPLL):&quot;, Xtrain.shape, Ytrain.shape)</span>

    <span class="c1"># ===========================</span>
    <span class="c1"># 3. Built-in GP Likelihood</span>
    <span class="c1"># ===========================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">Ytrain</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, mu: </span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, K: </span><span class="si">{</span><span class="n">K_gp</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">Ytrain</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">mean</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Ytrain</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">cov</span><span class="o">=</span><span class="n">K_gp</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LogProb: </span><span class="si">{</span><span class="n">log_prob</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">nll</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">nll</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="c1"># MEAN FUNCTION</span>
<span class="n">mu_f</span> <span class="o">=</span> <span class="n">zero_mean</span>

<span class="c1"># COVARIANCE FUNCTION</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;var_f&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="s1">&#39;likelihood_noise&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>


<span class="n">prior_funcs</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">)</span>
<span class="c1"># print(X.shape, y.shape, test_X.shape)</span>

<span class="n">nll</span> <span class="o">=</span> <span class="n">marginal_likelihood</span><span class="p">(</span><span class="n">prior_funcs</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nll</span><span class="p">)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:root:mu: (30,)
DEBUG:root:Kxx: (30, 30)
DEBUG:root:K_gp: (30, 30)
DEBUG:root:Input: (30,), mu: (30,), K: (30, 30)
DEBUG:absl:Compiling _einsum for args (ShapedArray(float32[30]), ShapedArray(float32[30])).
DEBUG:root:LogProb: ()
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>54.937344
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nll_scratch</span><span class="p">(</span><span class="n">prior_funcs</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">_</span> <span class="o">=</span> <span class="n">marginal_likelihood</span><span class="p">(</span><span class="n">prior_funcs</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

</div>
</div>
</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>18.3 ms  2.55 ms per loop (mean  std. dev. of 7 runs, 10 loops each)
26 ms  906 s per loop (mean  std. dev. of 7 runs, 10 loops each)
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="6-training">6. Training<a class="headerlink" href="#6-training" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>



<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">10.</span><span class="p">,</span>
<span class="c1">#     &#39;length_scale&#39;: 1.0,</span>
<span class="c1">#     &#39;var_f&#39;: 1.0,</span>
    <span class="s1">&#39;likelihood_noise&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Nice Trick for better training of params</span>
<span class="k">def</span> <span class="nf">saturate</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">ikey</span><span class="p">:</span><span class="n">softplus</span><span class="p">(</span><span class="n">ivalue</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">ikey</span><span class="p">,</span> <span class="n">ivalue</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">saturate</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="n">cov_f</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">gram</span><span class="p">,</span> <span class="n">rbf_kernel</span><span class="p">)</span>

<span class="n">gp_priors</span> <span class="o">=</span> <span class="p">(</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">cov_f</span><span class="p">)</span>

<span class="c1"># LOSS FUNCTION</span>
<span class="n">mll_loss</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">nll_scratch</span><span class="p">,</span> <span class="n">gp_priors</span><span class="p">))</span>

<span class="c1"># GRADIENT LOSS FUNCTION</span>
<span class="n">dloss</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">mll_loss</span><span class="p">))</span>



<span class="c1"># MEAN FUNCTION</span>
<span class="n">mu_f</span> <span class="o">=</span> <span class="n">zero_mean</span>


<span class="c1"># l_val = mll_loss(saturate(params), X[0,:], y[0, :].reshape(-1, 1))</span>
<span class="n">l_vals</span> <span class="o">=</span> <span class="n">mll_loss</span><span class="p">(</span><span class="n">saturate</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># print(&#39;MLL (vector):&#39;, l_val)</span>
<span class="c1"># print(&#39;MLL (samples):&#39;, l_vals)</span>


<span class="c1"># dl_val = dloss(saturate(params), X[0,:], y[0, :].reshape(-1, 1))</span>
<span class="n">dl_vals</span> <span class="o">=</span> <span class="n">dloss</span><span class="p">(</span><span class="n">saturate</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># print(&#39;dMLL (vector):&#39;, dl_val)|</span>
<span class="c1"># print(&#39;dMLL (samples):&#39;, dl_vals)</span>



<span class="c1"># STEP FUNCTION</span>
<span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">):</span>
    <span class="c1"># print(&quot;BEOFRE!&quot;)</span>
    <span class="c1"># print(X.shape, y.shape)</span>
    <span class="c1"># print(&quot;PARAMS&quot;, params)</span>
    <span class="c1"># print(opt_state)</span>
    <span class="c1"># value and gradient of loss function</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mll_loss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">dloss</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># # print(f&quot;VALUE:&quot;, value)</span>
    <span class="c1"># print(&quot;During! v&quot;, value)</span>
    <span class="c1"># print(&quot;During! p&quot;, params)</span>
    <span class="c1"># print(&quot;During! g&quot;, grads)</span>
    <span class="c1"># update parameter state</span>
    <span class="n">opt_state</span> <span class="o">=</span> <span class="n">opt_update</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>

    <span class="c1"># get new params</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">opt_state</span><span class="p">)</span>
    <span class="c1"># print(&quot;AFTER! v&quot;, value)</span>
    <span class="c1"># print(&quot;AFTER! p&quot;, params)</span>
    <span class="c1"># print(&quot;AFTER! g&quot;, grads)</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">loss</span>

<span class="c1"># initialize optimizer</span>
<span class="n">opt_init</span><span class="p">,</span> <span class="n">opt_update</span><span class="p">,</span> <span class="n">get_params</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>

<span class="c1"># initialize parameters</span>
<span class="n">opt_state</span> <span class="o">=</span> <span class="n">opt_init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># get initial parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">opt_state</span><span class="p">)</span>
<span class="c1"># print(&quot;PARAMS!&quot;, params)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2_000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">losses</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">tqdm</span>

<span class="k">with</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">trange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span> <span class="k">as</span> <span class="n">bar</span><span class="p">:</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bar</span><span class="p">:</span>
        <span class="n">postfix</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1">#         params = saturate(params)</span>
        <span class="c1"># get nll and grads</span>
        <span class="c1"># nll, grads = dloss(params, X, y)</span>

        <span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>

        <span class="c1"># update params</span>
        <span class="c1"># params, momentums, scales, nll = train_step(params, momentums, scales, X, y)</span>
        <span class="k">for</span> <span class="n">ikey</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">postfix</span><span class="p">[</span><span class="n">ikey</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">params</span><span class="p">[</span><span class="n">ikey</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># params[ikey] += learning_rate * grads[ikey].mean()</span>

        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">postfix</span><span class="p">[</span><span class="s2">&quot;Loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">onp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">postfix</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">saturate</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>


<span class="c1"># params = log_params(params)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2000/2000 [00:05&lt;00:00, 335.90it/s, gamma=1.58, likelihood_noise=-2.76, Loss=10.66]
</pre>
</div>
</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

</div>
</div>
<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="n">params</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>{&#39;gamma&#39;: 1.770868627016222, &#39;likelihood_noise&#39;: 0.06155753105145977}</pre>
</div>

</div>

<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing text_cell rendered">
<p><div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1"></p>
<h2 id="7-predictions">7. Predictions<a class="headerlink" href="#7-predictions" title="Permanent link">&para;</a></h2>
<p></div>
</div></p>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prior_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">likelihood_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, X: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Y: </span><span class="si">{</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, X*: </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="p">(</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_func</span><span class="p">)</span> <span class="o">=</span> <span class="n">prior_params</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded mean and cov functions&quot;</span><span class="p">)</span>

    <span class="c1"># ==========================</span>
    <span class="c1"># 1. GP PRIOR</span>
    <span class="c1"># ==========================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting GP Priors...&quot;</span><span class="p">)</span>

    <span class="n">mu_x</span><span class="p">,</span> <span class="n">Kxx</span> <span class="o">=</span> <span class="n">gp_prior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">mu_f</span><span class="o">=</span><span class="n">mu_func</span><span class="p">,</span> <span class="n">cov_f</span><span class="o">=</span><span class="n">cov_func</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, mu_x: </span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># check outputs</span>
    <span class="k">assert</span> <span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mu_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># ===========================</span>
    <span class="c1"># 2. CHOLESKY FACTORIZATION</span>
    <span class="c1"># ===========================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Solving Cholesky Factorization...&quot;</span><span class="p">)</span>

    <span class="c1"># 1 STEP</span>
<span class="c1">#     print(f&quot;Problem: {Kxx.shape},{Y.shape}&quot;)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span>
        <span class="n">Kxx</span> <span class="o">+</span> <span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;likelihood_noise&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, L: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span>
        <span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
        <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">)</span>
<span class="c1">#     (L, lower), alpha = cholesky_factorization(</span>
<span class="c1">#         , Y</span>
<span class="c1">#     )</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, L: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, alpha: </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">L</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;L:</span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= X..:</span><span class="si">{</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="n">alpha</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;alpha: </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= X: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># ================================</span>
    <span class="c1"># 4. PREDICTIVE MEAN DISTRIBUTION</span>
    <span class="c1"># ================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Projection Kernel...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, cov(x*, X): </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># calculate transform kernel</span>
    <span class="n">KxX</span> <span class="o">=</span> <span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, KxX: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="k">assert</span> <span class="n">KxX</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># Project data</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Mean Distribution...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, mu(x*): </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, KxX @ alpha: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> @ </span><span class="si">{</span><span class="n">alpha</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">mu_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, mu_y: </span><span class="si">{</span><span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># =====================================</span>
    <span class="c1"># 5. PREDICTIVE COVARIANCE DISTRIBUTION</span>
    <span class="c1"># =====================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Covariance matrix...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, L @ KxX.T: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> @ </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">#     print(f&quot;K_xX: {KXx.T.shape}, L: {L.shape}&quot;)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cho_solve</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, v: </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;v: </span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> =/= </span><span class="si">{</span><span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix tests...cov(x*, x*)&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, cov(x*, x*) - </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Kxx</span> <span class="o">=</span> <span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X_new</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calculating final covariance matrix...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, Kxx: </span><span class="si">{</span><span class="n">Kxx</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, v:</span><span class="si">{</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">cov_y</span> <span class="o">=</span> <span class="n">Kxx</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output: cov(x*, x*) - </span><span class="si">{</span><span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">likelihood_noise</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">cov_y</span> <span class="o">+=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;likelihood_noise&#39;</span><span class="p">]</span>

    <span class="c1"># TODO: Bug here for vmap...</span>

    <span class="c1"># =====================================</span>
    <span class="c1"># 6. PREDICTIVE VARIANCE DISTRIBUTION</span>
    <span class="c1"># =====================================</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Getting Predictive Variance...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input, L.T, I: </span><span class="si">{</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">Linv</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>


    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Linv: </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Covariance matrix tests...cov(x*, x*)&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, cov(x*, x*) - </span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">var_y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov_func</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X_new</span><span class="p">,</span> <span class="n">X_new</span><span class="p">))</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, diag(Kxx): </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, Linv @ Linv.T - </span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Linv</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Kinv</span> <span class="o">=</span>  <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Linv</span><span class="p">,</span> <span class="n">Linv</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, Kinv: </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final Variance...&quot;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inputs, KxX: </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">Kinv</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">KxX</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">var_y</span> <span class="o">-=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ij-&gt;i&quot;</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">KxX</span><span class="p">,</span> <span class="n">Kinv</span><span class="p">),</span> <span class="n">KxX</span><span class="p">)</span> <span class="c1">#jnp.dot(jnp.dot(KxX, Kinv), KxX.T)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output, var_y: </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">var_y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1">#jnp.einsum(&quot;ij, jk, ki-&gt;i&quot;, KxX, jnp.dot(Linv, Linv.T), KxX.T)</span>

    <span class="k">return</span> <span class="n">mu_y</span><span class="p">,</span> <span class="n">cov_y</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov_y</span><span class="p">)</span>
</code></pre></div>

</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">params</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>{&#39;gamma&#39;: 1.770868627016222, &#39;likelihood_noise&#39;: 0.06155753105145977}</pre>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># print(X.shape, y.shape, test_X.shape)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="c1"># x_plot = jnp.linspace(X.min(), X.max(), 1_000)[:, None]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">mu_y</span><span class="p">,</span> <span class="n">cov_y</span><span class="p">,</span> <span class="n">var_y</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">gp_priors</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mu_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cov_y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">var_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># onp.testing.assert_array_almost_equal(jncov_y, var_y)</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:root:Inputs, X: (30, 1), Y: (30, 1), X*: (400, 1)
DEBUG:root:Loaded mean and cov functions
DEBUG:root:Getting GP Priors...
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[30,1]), ShapedArray(float32[30,1])).
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(30, 1) (30, 1) (400, 1)
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stderr output_text">
<pre>DEBUG:root:Output, mu_x: (30,), Kxx: (30, 30)
DEBUG:root:Output, Kxx: (30, 30), 0.000838853360619396, 1.0
DEBUG:root:Solving Cholesky Factorization...
DEBUG:root:Output, L: (30, 30),0.0,1.0303192138671875 
DEBUG:absl:Compiling _solve_triangular for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,1])).
DEBUG:absl:Compiling _solve_triangular for args (ShapedArray(float32[30,30]), ShapedArray(float32[30,1])).
DEBUG:root:Output, L: (30, 30), alpha: (30, 1),-8.470149993896484,10.187272071838379 
DEBUG:root:Getting Projection Kernel...
DEBUG:root:Input, cov(x*, X): (400, 1),(30, 1)
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[400,1]), ShapedArray(float32[30,1])).
DEBUG:root:Output, KxX: (400, 30)
DEBUG:root:Getting Predictive Mean Distribution...
DEBUG:root:Input, mu(x*): (400, 1), KxX @ alpha: (400, 30) @ (30, 1)
DEBUG:root:Output, mu_y: (400, 1)
DEBUG:root:Getting Predictive Covariance matrix...
DEBUG:root:Input, L @ KxX.T: (30, 30) @ (30, 400)
DEBUG:root:Output, v: (30, 400), -0.17,0.75
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (400, 1),(400, 1)
DEBUG:absl:Compiling rbf_kernel for args (ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[400,1]), ShapedArray(float32[400,1])).
DEBUG:root:Output, Kxx: (400, 400)
DEBUG:root:Calculating final covariance matrix...
DEBUG:root:Inputs, Kxx: (400, 400), v:(30, 400)
DEBUG:root:Output: cov(x*, x*) - (400, 400)
DEBUG:root:Getting Predictive Variance...
DEBUG:root:Input, L.T, I: (30, 30), (30, 400)
DEBUG:root:Output, Linv: (30, 30), -2.54,3.05
DEBUG:root:Covariance matrix tests...cov(x*, x*)
DEBUG:root:Inputs, cov(x*, x*) - (400, 1),(400, 1)
DEBUG:root:Output, diag(Kxx): (400,), 1.00,1.00
DEBUG:root:Inputs, Linv @ Linv.T - (30, 30),(30, 30)
DEBUG:root:Output, Kinv: (30, 30), -5.07,13.96
DEBUG:root:Final Variance...
DEBUG:root:Inputs, KxX: (400, 30), (30, 30), (400, 30)
DEBUG:absl:Compiling _einsum for args (ShapedArray(float32[400,30]), ShapedArray(float32[400,30])).
DEBUG:root:Output, var_y: (400,), 0.01,0.12
</pre>
</div>
</div>

<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(400, 1) (400, 400) (400,)
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">var_y</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">var_y</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">cov_y</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">cov_y</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">var_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>0.07021278 0.18080568 0.05092573 0.18080568
</pre>
</div>
</div>

<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f065c01e5b0&gt;]</pre>
</div>

</div>

<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="n">uncertainty</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mean&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">+</span> <span class="n">uncertainty</span><span class="p">,</span> <span class="n">mu_y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">uncertainty</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code>
</code></pre></div>

</div>
</div>
</div>
</div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../../vi/" title="Uncertain Inputs GPs - Variational Strategies" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Uncertain Inputs GPs - Variational Strategies
              </div>
            </div>
          </a>
        
        
          <a href="../1.1_gp_refactored/" title="1.1 gp refactored" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                1.1 gp refactored
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 J. Emmanuel Johnson
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
  <div class="md-footer-social">
    
      
      
      <a href="https://github.com/jejjohnson" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
      
      
      <a href="https://twitter.com/jejjohnson" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
      
      
      <a href="https://linkedin.com/in/jejjohnson" target="_blank" rel="noopener" title="linkedin.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
    
      
      
      <a href="https://jejjohnson.netlify.com" target="_blank" rel="noopener" title="jejjohnson.netlify.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.83fe6e3c.min.js"></script>
      <script src="../../assets/javascripts/bundle.7e1cb91c.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.37585f48.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>