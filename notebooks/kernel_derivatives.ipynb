{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4EJ9PyKoMdb"
   },
   "source": [
    "# Kernel Derivatives\n",
    "\n",
    "\n",
    "**Resources**\n",
    "\n",
    "* [Differentating Gaussian Processes](http://mlg.eng.cam.ac.uk/mchutchon/DifferentiatingGPs.pdf) - Andrew McHutchen\n",
    "\n",
    "## Paper Idea\n",
    "\n",
    "**Linear Operators and Stochastic Partial Differential Equations in GPR** - Simo Särkkä - [PDF](https://users.aalto.fi/~ssarkka/pub/spde.pdf)\n",
    "\n",
    "> Expresses derivatives of GPs as operators\n",
    "\n",
    "[**Demo Colab Notebook**](https://colab.research.google.com/drive/1pbb0qlypJCqPTN_cu2GEkkKLNXCYO9F2)\n",
    "\n",
    "He looks at ths special case where we have a GP with a mean function zero and a covariance matrix $K$ defined as:\n",
    "$$\n",
    "\\mathbb{E}[f(\\mathbf{x})f^\\top(\\mathbf{x'})] = K_{ff}(\\mathbf{x,x'})\n",
    "$$\n",
    "So in GP terminology:\n",
    "$$\n",
    "f(\\mathbf(x)) \\sim \\mathcal{GP}(\\mathbf{0}, K_{ff}(\\mathbf{x,x'}))\n",
    "$$\n",
    "We use the rulse for linear transformations of GPs to obtain the different transformations of the kernel matrix. \n",
    "\n",
    "Let's define the notation for the derivative of a kernel matrix. Let $g(\\cdot)$ be the derivative operator on a function $f(\\cdot)$. So:\n",
    "$$\n",
    "g(\\mathbf{x}) = \\mathcal{L}_x f(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "So now, we want to define the cross operators between the derivative $g(\\cdot)$ and the function $f(\\cdot)$. \n",
    "\n",
    "**Example**: He draws a distinction between the two operators with an example of how this works in practice. So let's take the linear operator $\\mathcal{L}_{x}=(1, \\frac{\\partial}{\\partial x})$. This operator:\n",
    "\n",
    "* acts on a scalar GP $f(x)$\n",
    "* a scalar input $x$ \n",
    "* a covariance function $k_{ff}(x,x')$ \n",
    "* outputs a scalar value $y$\n",
    "\n",
    "\n",
    "\n",
    "We can get the following transformations:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K_{gf}(\\mathbf{x,x'})\n",
    "&= \\mathcal{L}_x f(\\mathbf{x}) f(\\mathbf{x}) = \\mathcal{L}_xK_{ff}(\\mathbf{x,x'}) \\\\\n",
    "K_{fg}(\\mathbf{x,x'})\n",
    "&= f(\\mathbf{x}) f(\\mathbf{x'}) \\mathcal{L}_{x'} = K_{ff}(\\mathbf{x,x'})\\mathcal{L}_{x'} \\\\\n",
    "K_{gg}(\\mathbf{x,x'})\n",
    "&= \\mathcal{L}_x f(\\mathbf{x}) f(\\mathbf{x'}) \\mathcal{L}_{x'}\n",
    "= \\mathcal{L}_xK_{ff}(\\mathbf{x,x'})\\mathcal{L}_{x'}^\\top \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "kV8wRfKbYE92"
   },
   "outputs": [],
   "source": [
    "#@title Packages\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "from sklearn.metrics.pairwise import rbf_kernel as rbf_sklearn\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn-paper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Plot Functions\n",
    "\n",
    "def plot_kernel_mat(K):\n",
    "    # plot\n",
    "    plt.figure()\n",
    "    plt.imshow(K, cmap='Reds')\n",
    "    plt.title(r'$K_{ff}$, (rbf)', fontsize=20, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "z0-afZT_YZqo",
    "outputId": "55ff8e6e-758f-4d11-eda3-ae94b824e365"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/.conda/envs/jax_py38/lib/python3.8/site-packages/jax/lib/xla_bridge.py:123: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "#@title Data\n",
    "\n",
    "def get_1d_data(N=30, sigma_inputs=0.15, sigma_obs=0.15, N_test=400):\n",
    "    onp.random.seed(0)\n",
    "    X = jnp.linspace(-10, 10, N)\n",
    "    # Y = X + 0.2 * np.power(X, 3.0) + 0.5 * np.power(0.5 + X, 2.0) * np.sin(4.0 * X)\n",
    "    Y = jnp.sin(1.0 * jnp.pi / 1.6 * jnp.cos(5 + .5 * X))\n",
    "    Y += sigma_obs * onp.random.randn(N)\n",
    "    X += sigma_inputs * onp.random.randn(N)\n",
    "    Y -= jnp.mean(Y)\n",
    "    Y /= jnp.std(Y)\n",
    "\n",
    "\n",
    "\n",
    "    X_test = jnp.linspace(-11, 11, N_test) \n",
    "    X_test += sigma_inputs * onp.random.randn(N_test)\n",
    "\n",
    "    X = X[:, None]\n",
    "    X_test = X[:, None]\n",
    "\n",
    "    assert X.shape == (N,1)\n",
    "    assert Y.shape == (N,)\n",
    "\n",
    "    return X, Y, X_test\n",
    "\n",
    "def get_2d_data(N=30, sigma_obs=0.15, N_test=400):\n",
    "    onp.random.seed(0)\n",
    "    X1 = jnp.linspace(-10, 10, N)\n",
    "    X2 = jnp.linspace(-5, 2, N)\n",
    "    # Y = X + 0.2 * np.power(X, 3.0) + 0.5 * np.power(0.5 + X, 2.0) * np.sin(4.0 * X)\n",
    "    Y = jnp.sin(1.0 * jnp.pi / 1.6 * jnp.cos(5 + .5 * X1)) + jnp.exp(X2)\n",
    "    Y += sigma_obs * onp.random.randn(N)\n",
    "    Y -= jnp.mean(Y)\n",
    "    Y /= jnp.std(Y)\n",
    "\n",
    "\n",
    "\n",
    "    X1_test = jnp.linspace(-11, 11, N_test)\n",
    "    X2_test = jnp.linspace(-6, 4, N_test) \n",
    "\n",
    "    X = jnp.vstack((X1,X2)).T\n",
    "    X_test = jnp.vstack((X1_test,X2_test)).T\n",
    "\n",
    "    assert X.shape == (N,2)\n",
    "    assert Y.shape == (N,)\n",
    "\n",
    "    return X, Y, X_test\n",
    "\n",
    "# Get Data\n",
    "X, Y, X_test = get_1d_data(100, sigma_inputs=0.0, sigma_obs=0.1, N_test=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbQXQEp6yWIq"
   },
   "source": [
    "## Kernel Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fz32W8cRyXNi"
   },
   "outputs": [],
   "source": [
    "#@title Kernel Functions\n",
    "\n",
    "# Squared Euclidean Distance Formula\n",
    "@jax.jit\n",
    "def sqeuclidean_distance(x, y):\n",
    "    return jnp.sum((x-y)**2)\n",
    "\n",
    "# RBF Kernel\n",
    "@jax.jit\n",
    "def rbf_kernel(params, x, y):\n",
    "    return jnp.exp( - params['gamma'] * sqeuclidean_distance(x, y))\n",
    "    \n",
    "# Covariance Matrix\n",
    "def covariance_matrix(kernel_func, x, y):\n",
    "    mapx1 = jax.vmap(lambda x, y: kernel_func(x, y), in_axes=(0, None), out_axes=0)\n",
    "    mapx2 = jax.vmap(lambda x, y: mapx1(x, y), in_axes=(None, 0), out_axes=1)\n",
    "    return mapx2(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "X, Y, X_test = get_2d_data(10, sigma_obs=0.1)\n",
    "\n",
    "test_X = X[:1, :]\n",
    "test_Y = X[:1, :]\n",
    "\n",
    "rbf_x_sk = rbf_sklearn(\n",
    "    onp.array(test_X.reshape(1, -1)), \n",
    "    onp.array(test_Y.reshape(1, -1)), \n",
    "    gamma=1.0\n",
    ")\n",
    "print(rbf_x_sk.shape, test_X.shape)\n",
    "\n",
    "params = {'gamma': 1.0, 'var_f': 1.0}\n",
    "gamma=1.0\n",
    "rbf_k_ = functools.partial(rbf_kernel, params)\n",
    "rbf_x = rbf_k_(\n",
    "    test_X.squeeze(), \n",
    "    test_Y.squeeze()\n",
    ")\n",
    "\n",
    "onp.testing.assert_array_almost_equal(onp.array(rbf_x), rbf_x_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Matrix\n",
    "\n",
    "We defined all of our functions above with only dimensions in mind, not the number of samples or the batch size. So we need to account for that. So if we wanted to calculate the kernel matrix, we would have to loop through all of the samples and calculate the products individually, which would take a long time; especially for large amounts of data. \n",
    "\n",
    "> Avoid Loops at all cost in python...\n",
    "\n",
    "Fortunately, Jax has this incredible function `vmap` which handles batching automatically at apparently, no extra cost. So we can write our functions to account for vectors without having to care about the batch size and then use the `vmap` function to essentially \"vectorize\" our functions. It essentially allows us to take a product between a matrix and a sample or two vectors of multiple samples. Let's go through an example of how we can construct our kernel matrix.\n",
    "\n",
    "1. We need to map all points with one vector to another.\n",
    "\n",
    "We're going to take a single sample from $X'$ and take the rbf kernel between it and all of $X$. So:\n",
    "\n",
    "$$\\text{vmap}_f(\\mathbf{X}, \\mathbf{x})$$\n",
    "\n",
    "where $X\\in \\mathbb{R}^{N \\times D}$ is a matrix and $\\mathbf{x} \\in \\mathbb{R}^{D}$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram Matrix\n",
    "def gram(func, x, y):\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(x1, y1))(y))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map function 1\n",
    "mapx1 = jax.vmap(lambda x, y: rbf_kernel(params, x, y), in_axes=(0, None), out_axes=0)\n",
    "\n",
    "# test the mapping\n",
    "x1_mapped = mapx1(X, X[0, :])\n",
    "\n",
    "# Check output shapes, # of dimensions\n",
    "assert x1_mapped.shape[0] == X.shape[0]   \n",
    "assert jnp.ndim(x1_mapped) == 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This that's good: we have an array of size $N$. So we've effectively mapped all points from one array to the other. \n",
    "\n",
    "So now we can do another vector mapping which allows us to take all samples of $X'$ and map them against all samples of $X$. So it'll be a `vmap` of a `vmap`. Then we'll get the $N\\times N$ kernel matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapx2 = jax.vmap(lambda x, y: mapx1(x, y), in_axes=(None, 0), out_axes=1)\n",
    "\n",
    "K = mapx2(X, X)\n",
    "\n",
    "# Check output shapes, # of dimensions\n",
    "assert K.shape[0] == X.shape[0], X.shape[0]   \n",
    "assert jnp.ndim(K) == 2     \n",
    "\n",
    "rbf_x_sk = rbf_sklearn(X, X, 1.0)\n",
    "\n",
    "\n",
    "onp.testing.assert_array_almost_equal(onp.array(rbf_x_sk), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So great! We now have our kernel matrix. Let's plot it and check to see if it matches the manually constructed kernel matrix.\n",
    "\n",
    "Great! We have a vectorized kernel function and we were still able to construct our functions in terms of vectors only! This is nice for me personally because I've always struggled with understanding some of the coding when trying to deal with samples/batch-sizes. Most pseudo-code is written in vector format so paper $\\rightarrow$ has always been a painful transition for me. So now, let's wrap this in a nice function so that we can finish \"wrap up\" this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJmi7gqwyY5U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x316.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y, X_test = get_2d_data(10, sigma_obs=0.1)\n",
    "\n",
    "test_X = X.copy()#[:2, :]\n",
    "test_Y = X.copy() #[:2, :]\n",
    "\n",
    "rbf_x_sk = rbf_sklearn(\n",
    "    onp.array(test_X), \n",
    "    onp.array(test_Y), \n",
    "    gamma=1.0\n",
    ")\n",
    "\n",
    "params = {'gamma': 1.0, 'var_f': 1.0}\n",
    "rbf_k_ = functools.partial(rbf_kernel, params)\n",
    "rbf_x = covariance_matrix(\n",
    "    rbf_k_,\n",
    "    test_X, \n",
    "    test_Y\n",
    ")\n",
    "\n",
    "onp.testing.assert_array_almost_equal(onp.array(rbf_x), rbf_x_sk)\n",
    "\n",
    "plot_kernel_mat(rbf_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "L81uQDJmY8Ig"
   },
   "outputs": [],
   "source": [
    "#@title Tests\n",
    "\n",
    "kx = rbf_kernel(params, X[0], X[0])\n",
    "\n",
    "# check, the output should be 1.0\n",
    "assert kx == 1.0, f\"Output: {kx}\"\n",
    "\n",
    "kx = rbf_kernel(params, X[0], X[1])\n",
    "\n",
    "# check, the output should NOT be 1.0\n",
    "assert kx != 1.0, f\"Output: {kx}\"\n",
    "\n",
    "\n",
    "# dk_dx = drbf_kernel(gamma, X[0], X[0])\n",
    "\n",
    "# # check, the output should be 0.0\n",
    "# assert dk_dx == 0.0, f\"Output: {dk_dx}\"\n",
    "\n",
    "# dk_dx = drbf_kernel(gamma, X[0], X[1])\n",
    "\n",
    "# # check, the output should NOT be 0.0\n",
    "# assert dk_dx != 0.0, f\"Output: {dk_dx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Speed Test\n",
    "    \n",
    "# Covariance Matrix\n",
    "def covariance_matrix(kernel_func, x, y):\n",
    "    mapx1 = jax.vmap(lambda x, y: kernel_func(x, y), in_axes=(0, None), out_axes=0)\n",
    "    mapx2 = jax.vmap(lambda x, y: mapx1(x, y), in_axes=(None, 0), out_axes=1)\n",
    "    return mapx2(x, y)\n",
    "\n",
    "def gram(func, x, y):\n",
    "    return jax.vmap(lambda x1: jax.vmap(lambda y1: func(x1, y1))(x))(y)\n",
    "\n",
    "rbf_K = functools.partial(rbf_kernel, params)\n",
    "rbf_cov =  jax.jit(functools.partial(covariance_matrix, rbf_K))\n",
    "rbf_x = rbf_cov(test_X,  test_Y)\n",
    "\n",
    "\n",
    "rbf_cov2 =  jax.jit(functools.partial(gram, rbf_K))\n",
    "rbf_x2 = rbf_cov2(test_X,  test_Y)\n",
    "\n",
    "onp.testing.assert_array_almost_equal(onp.array(rbf_x), onp.array(rbf_x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 µs ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "167 µs ± 941 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = rbf_cov(test_X,  test_Y)\n",
    "%timeit _ = rbf_cov2(test_X,  test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wK14aQKmDbi"
   },
   "source": [
    "## 1. Cross-Covariance Term - 1st Derivative\n",
    "\n",
    "\n",
    "We can calculate the cross-covariance term $K_{fg}(\\mathbf{x,x})$. We apply the following operation\n",
    "\n",
    "$$\n",
    "K_{fg}(x,x') = k_{ff}(\\mathbf{x,x'})(1, \\frac{\\partial}{\\partial x'})\n",
    "$$\n",
    "If we multiply the terms across, we get:\n",
    "$$\n",
    "K_{fg}(x,x') = k_{ff}(\\mathbf{x,x'})\\frac{\\partial k_{ff}(\\mathbf{x,x'})}{\\partial x'}\n",
    "$$\n",
    "\n",
    "For the RBF Kernel, it's this:\n",
    "\n",
    "$$\\frac{\\partial k(x,y)}{\\partial x^j}=-2 \\gamma (x^j - y^j) k(x,y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_test = get_1d_data(10, sigma_obs=0.1)\n",
    "\n",
    "test_X = X[0:1, :]\n",
    "test_Y = X[1:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EningAbiuJf-"
   },
   "source": [
    "#### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drbf_kernel_scratch(gamma, X, Y):\n",
    "    dK_fg_ = onp.empty(X.shape[-1])\n",
    "    \n",
    "    constant = - 2 * gamma\n",
    "    \n",
    "    k_val = rbf_sklearn(onp.array(X), onp.array(Y), gamma=gamma)\n",
    "    \n",
    "    for idim in range(X.shape[1]):\n",
    "        \n",
    "        x_val = X[:, idim] - Y[:, idim]\n",
    "\n",
    "        dK_fg_[idim] = constant * k_val *  x_val \n",
    "    return dK_fg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01392619]\n"
     ]
    }
   ],
   "source": [
    "dK_fg_ = drbf_kernel_scratch(gamma, test_X, test_Y)\n",
    "print(dK_fg_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01392619]\n"
     ]
    }
   ],
   "source": [
    "# define the cross operator K_fg(x, y), dK wrt x\n",
    "drbf_kernel_fg = jax.jacobian(rbf_kernel, argnums=(1))\n",
    "\n",
    "# calculate for a single sample\n",
    "dK_fg = drbf_kernel_fg(params, test_X[0,:], test_Y[0,:])\n",
    "print(dK_fg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_test = get_2d_data(10, sigma_obs=0.1)\n",
    "\n",
    "test_X = X[0:1, :]\n",
    "test_Y = X[1:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0173953  0.00608835]\n"
     ]
    }
   ],
   "source": [
    "dK_fg_ = drbf_kernel_scratch(gamma, test_X, test_Y)\n",
    "print(dK_fg_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0173953  0.00608835]\n"
     ]
    }
   ],
   "source": [
    "# define the cross operator K_fg(x, y), dK wrt x\n",
    "drbf_kernel_fg = jax.jacobian(rbf_kernel, argnums=(1))\n",
    "\n",
    "# calculate for a single sample\n",
    "dK_fg = drbf_kernel_fg(params, test_X[0,:], test_Y[0,:])\n",
    "print(dK_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Samples (Batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_test = get_2d_data(10, sigma_obs=0.1)\n",
    "\n",
    "test_X = X\n",
    "test_Y = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dK_fg_ = onp.empty((test_X.shape[0], test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    for j in range(test_Y.shape[0]):\n",
    "        \n",
    "        dK_fg_[i, j, :] = drbf_kernel_scratch(gamma, onp.array(test_X[i, :]).reshape(1,-1), onp.array(test_Y[j, :]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cross operator K_fg(x, y), dK wrt x\n",
    "drbf_kernel_fg = jax.jacobian(rbf_kernel, argnums=(1))\n",
    "\n",
    "K_func = functools.partial(drbf_kernel_fg, params)\n",
    "dK_fg = gram(K_func, test_X, test_Y)\n",
    "\n",
    "\n",
    "onp.testing.assert_array_almost_equal(onp.array(dK_fg), dK_fg_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cross-Covariance Term - 2nd Derivative\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 k(x,y)}{\\partial x^{j^2}} =\n",
    "2 \\gamma \\left[ 2\\gamma(x^j - y^j)^2 - 1\\right] k(\\mathbf{x}, \\mathbf{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2rbf_kernel_scratch_jac(gamma, X, Y):\n",
    "    d2K_fg2_ = onp.empty(X.shape[-1])\n",
    "    \n",
    "    constant = 2 * gamma\n",
    "    \n",
    "    k_val = rbf_sklearn(onp.array(X), onp.array(Y), gamma=gamma)\n",
    "    \n",
    "    for idim in range(X.shape[1]):\n",
    "        \n",
    "        x_val = constant * (X[:, idim] - Y[:, idim]) ** 2 - 1\n",
    "\n",
    "        d2K_fg2_[idim] = constant * k_val *  x_val \n",
    "    return d2K_fg2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2K_fg2_ = onp.empty((test_X.shape[0], test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    for j in range(test_Y.shape[0]):\n",
    "        \n",
    "        d2K_fg2_[i, j, :] = d2rbf_kernel_scratch_jac(gamma, onp.array(test_X[i, :]).reshape(1,-1), onp.array(test_Y[j, :]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the cross operator K_fg(x, y), dK wrt x\n",
    "dK_fg_func = jax.hessian(rbf_kernel, argnums=(1))\n",
    "\n",
    "K_func = functools.partial(dK_fg_func, params)\n",
    "d2K_fg2 = covariance_matrix(K_func, test_X, test_Y)\n",
    "\n",
    "d2K_fg2 = jnp.diagonal(d2K_fg2, axis1=2, axis2=3)\n",
    "\n",
    "d2K_fg2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.testing.assert_array_almost_equal(onp.array(d2K_fg2), d2K_fg2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Covariance Term - 2nd Derivative (Partial Derivatives)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 k(x,y)}{\\partial x^j \\partial y^k} =\n",
    "4 \\gamma^2 (x^k - y^k)(x^j - y^j) k(\\mathbf{x}, \\mathbf{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2rbf_kernel_scratch_hessian(gamma, X, Y):\n",
    "    d2K_fg2_ = onp.empty((X.shape[-1], X.shape[-1]))\n",
    "    \n",
    "    constant = 2 * gamma\n",
    "    constant_sq = constant ** 2\n",
    "    \n",
    "    k_val = rbf_sklearn(onp.array(X), onp.array(Y), gamma=gamma)\n",
    "    \n",
    "    for idim in range(X.shape[1]):\n",
    "        for jdim in range(X.shape[1]):\n",
    "        \n",
    "            x_val = constant * (1 - constant * (X[:, idim] - Y[:, idim]) * (X[:, jdim] - Y[:, jdim]))# - constant\n",
    "\n",
    "            d2K_fg2_[idim, jdim] = k_val *  x_val \n",
    "    return d2K_fg2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2K_fg2_ = onp.empty((test_X.shape[0], test_X.shape[0], test_X.shape[1], test_X.shape[1]))\n",
    "\n",
    "for i in range(test_X.shape[0]):\n",
    "    for j in range(test_Y.shape[0]):\n",
    "        \n",
    "        d2K_fg2_[i, j, ...] = d2rbf_kernel_scratch_hessian(gamma, onp.array(test_X[i, :]).reshape(1,-1), onp.array(test_Y[j, :]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 2, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the cross operator K_fg(x, y), dK wrt x\n",
    "dK_fg_func = jax.hessian(rbf_kernel, argnums=(1))\n",
    "\n",
    "K_func = functools.partial(dK_fg_func, params)\n",
    "d2K_fg2 = covariance_matrix(K_func, test_X, test_Y)\n",
    "\n",
    "d2K_fg2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.testing.assert_array_almost_equal(onp.array(onp.diagonal(d2K_fg2, axis1=2, axis2=3 )), jnp.diagonal(d2K_fg2, axis1=2, axis2=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 6 decimals\n\nMismatched elements: 112 / 400 (28%)\nMax absolute difference: 4.\nMax relative difference: 2.40703559\n x: array([[[[-2.000000e+00,  0.000000e+00],\n         [ 0.000000e+00, -2.000000e+00]],\n...\n y: array([[[[ 2.000000e+00,  2.000000e+00],\n         [ 2.000000e+00,  2.000000e+00]],\n...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a1b4fece15e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2K_fg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2K_fg2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/jax_py38/lib/python3.8/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(x, y, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n\u001b[0m\u001b[1;32m   1046\u001b[0m              \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arrays are not almost equal to %d decimals'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m              precision=decimal)\n",
      "\u001b[0;32m~/.conda/envs/jax_py38/lib/python3.8/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 6 decimals\n\nMismatched elements: 112 / 400 (28%)\nMax absolute difference: 4.\nMax relative difference: 2.40703559\n x: array([[[[-2.000000e+00,  0.000000e+00],\n         [ 0.000000e+00, -2.000000e+00]],\n...\n y: array([[[[ 2.000000e+00,  2.000000e+00],\n         [ 2.000000e+00,  2.000000e+00]],\n..."
     ]
    }
   ],
   "source": [
    "onp.testing.assert_array_almost_equal(onp.array(d2K_fg2), d2K_fg2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "kernel_derivatives.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jax_py38]",
   "language": "python",
   "name": "conda-env-.conda-jax_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
